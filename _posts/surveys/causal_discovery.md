---
title: Causal Discovery
date: 2021-08-25 12:00:00
updated: 2022-11-17 18:19:00
tag: 
- survey
- causal discovery
- structural causal model
- toolbox
- paper list
- note
---

- è°ƒç ”è¿‘å¹´å› æœå‘ç°çš„æœ€æ–°ç ”ç©¶
- å°†"å› æœå‘ç°"ä¸"æ ¹å› åˆ†æ"ä»¥åŠ"åŸºäºå› æœå›¾çš„å› æœå‘ç°"ç­‰æ¦‚å¿µç†æ¸…å…³ç³»
- ä»ä¼˜åŒ–çš„è§’åº¦é‡æ–°çœ‹å¾…ä¸‰ç±»å› æœå‘ç°ç®—æ³•, è¿™å¯ä»¥å¸®åŠ©æˆ‘ä»¬å€Ÿé‰´å·²æœ‰æ–¹æ³•åˆ°è‡ªå·±çš„å·¥ä½œä¸­ã€‚
- æ€»ç»“ç”¨äºå› æœå‘ç°çš„å„ç§åŒ…, ä»¥åŠGithubä¸Šstarè¾ƒå¤šçš„Repositories

<!-- more -->

## å› æœä¸‰é˜¶æ¢¯

**Causal discovery(CD)** åŒ…å«ä¸‰ä¸ªå±‚æ¬¡ <a href="#ref1">[1]</a>: 

- å…³è” *Association*: Aã€Bç›¸å…³
- å¹²é¢„ *Intervention*: æ”¹å˜Açš„æ—¶å€™, Bå¦‚ä½•æ”¹å˜
- åäº‹å® *Counterfactuals*: è¦æƒ³æ”¹å˜B, åº”è¯¥å¦‚ä½•æ”¹å˜A

äº‹å®ä¸Š, è®¸å¤šCDçš„æ–¹æ³•éƒ½ä»…èƒ½åšåˆ°**å‰ä¸¤ä¸ªé˜¶æ®µ**ã€‚"åäº‹å®"é€šå¸¸æ˜¯ä¸å¯å®ç°çš„, å› ä¸º"åäº‹å®"è¦æ±‚åœ¨ä¸<u>å†å²å®Œå…¨ç›¸åŒçš„ç¯å¢ƒå› ç´ </u>ä¸‹**æ¢ç©¶å†³ç­–å¯¹ä¸ªä½“çš„å½±å“**ã€‚



## å› æœçš„æœ¬è´¨ã€æ•°å­¦è¡¨è¾¾ ä¸ å› æœç»“æ„å­¦ä¹ 

è¿™ä¸€èŠ‚çš„åˆ†ææºè‡ªä¸‹é¢å¯¹ä¸‰ç±»causal structure learningæ–¹æ³•æŒ–æ˜çš„å› æœæœ¬è´¨çš„æ€è€ƒã€‚åæ–‡ä¸­å·²ç»åˆ†æå¾—å‡ºï¼Œä¸‰ç±»causal structure learningæ–¹æ³•å‘ç°çš„å› æœéƒ½åªåœç•™åœ¨ç”±â€œæ¡ä»¶ä¾èµ–â€æˆ–è€…â€œå›å½’â€æ‰€åˆ»ç”»çš„â€œ**å…³è”å…³ç³»**â€ï¼Œè€ŒéçœŸæ­£çš„å› æœå…³ç³»ï¼Œå› æ­¤æœ¬èŠ‚çš„ä¸»é¢˜æ˜¯

- è°ƒç ”casual discoveryå’Œcausal structure learningä¹‹é—´çš„åŒºåˆ«ï¼ˆè¿™ä¸ªé—®é¢˜å’Œå“²å­¦ä¸Šçš„å› æœå®šä¹‰æœ‰å…³ï¼‰
- é™¤äº†DAGè¡¨ç¤ºçš„å› æœå›¾å¤–ï¼Œè¿˜æœ‰å“ªäº›è¡¨å¾å› æœçš„æ¨¡å‹èŒƒå¼ï¼ˆDAGå› æœå›¾å°±æ˜¯èŠ‚ç‚¹ä»£è¡¨å˜é‡ï¼Œè¾¹ä»£è¡¨ç›´æ¥åŸå› çš„å›¾æ¨¡å‹ï¼‰

è¦åˆ†æcausal discoveryå’Œcausal structure learningä¹‹é—´çš„åŒºåˆ«ï¼Œæœ‰ä»¥ä¸‹æ€è·¯ï¼š

- å·²çŸ¥causal structure learningä¸­ï¼Œå·²ç»ç”¨ä¸åŒçš„æ¨¡å‹å¯¹å› æœè¿›è¡Œäº†å®šä¹‰ï¼Œè¿™ç§å®šä¹‰æˆ–æ˜¯å®šæ€§çš„ã€æˆ–æ˜¯å®šé‡çš„ï¼Œå› æ­¤è¿™ç±»æ–¹æ³•æœ¬è´¨ä¸Šå°±æ˜¯åœ¨æ ¹æ®æ¯ç§æ–¹æ³•çš„å®šä¹‰ï¼Œä»æ•°æ®ä¸­æ‹Ÿåˆæ‰€è°“çš„â€œå› æœâ€ã€‚å› æ­¤causal structure learningå¯ä»¥è§†ä¸ºâ€œå­¦ä¹ ä»¥æ¨¡å‹å®šä¹‰çš„å› æœâ€çš„ä¸€ç±»æ–¹æ³•

- é‚£é™¤äº†ç”¨æ¨¡å‹å®šä¹‰çš„å› æœï¼Œè¿˜æœ‰å“ªäº›å®šä¹‰å‘¢ã€‚

    

### å› æœçš„æœ¬è´¨

æ–‡çŒ®<a href="#ref14">[14]</a>ä»å“²å­¦ã€ç¤¾ä¼šå­¦ç­‰å±‚é¢æ¢ç©¶äº†å› æœåœ¨AIé¢†åŸŸçš„å®šä¹‰ï¼Œåœ¨Section 6.5ä¸­æåˆ°äº†ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šâ€œå› æœæ˜¯**ç¡®å®šæ€§**çš„è¿˜æ˜¯**æ¦‚ç‡æ€§**çš„ï¼Ÿâ€ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›ç»“è®ºï¼šè‡ªå¤ä»¥æ¥ï¼Œå› æœè¿™ä¸ªæ¦‚å¿µéƒ½**ä¸å…·å¤‡ä¸€ä¸ªç»Ÿä¸€çš„å®šä¹‰**ã€‚è‡ªå¤ä»¥æ¥ï¼Œå› æœæ€»æ˜¯ä¸å†³å®šè®ºã€ç‰©ç†å¿…ç„¶æ€§å’Œé€»è¾‘å¿…ç„¶æ€§è”ç³»åœ¨ä¸€èµ·ï¼ˆå³ï¼š**ç¡®å®šæ€§**ï¼‰ã€‚ä½†åœ¨ç°ä»£ç§‘å­¦æ‰€ç ”ç©¶çš„å› æœç†è®ºå‡ ä¹éƒ½æ˜¯**æ¦‚ç‡æ€§**çš„ï¼Œå³ä»¥æ¦‚ç‡è®ºå’Œç»Ÿè®¡å­¦è®ºä¸ºåŸºç¡€çš„ã€‚ä½†ä¹Ÿæœ‰éƒ¨åˆ†ç¡®å®šæ€§çš„è¡¨è¿°ï¼Œè¿™ç§è¡¨è¿°å¤§å¤šæºè‡ªäºå·¥ç¨‹å­¦ï¼Œæ˜¯ä¸€ç§ä¸è¯è‡ªæ˜æ–¹æ³•ï¼ˆè¿™é‡Œæˆ‘ç†è§£ï¼Œåœ¨å·¥ç¨‹å­¦é‡Œæ€»æœ‰â€œæ”¹å˜Aï¼ŒåŸºäºè®¾è®¡åŸç†ï¼ŒBå°±ä¸€å®šä¼šæ”¹å˜ï¼Œå¹¶ä¸”Båªå—Aæ§åˆ¶ï¼Œå› æ­¤ABæ˜¯å› æœå…³ç³»â€çš„è¡¨è¿°ï¼Œè¿™ç§å·¥ç¨‹å­¦ä¸Šçš„å› æœæ˜¾ç„¶æ˜¯ç¡®å®šæ€§çš„ï¼‰ã€‚

å…¶å®ï¼Œå› æœåœ¨ç»Ÿè®¡å­¦ä¸Šçš„å®šä¹‰ä¹Ÿå¹¶æœªç»Ÿä¸€ï¼Œæ–‡çŒ®<a href="#ref16">[16]</a>ä¸­åˆ—å‡ºäº†ä¸‰ç§ä¸»è¦çš„è§‚ç‚¹ï¼Œä¸‹æ–‡è¯´æ˜ä¸€ç§è¾ƒå¸¸è§çš„è§‚ç‚¹ï¼Œæ¥è‡ªäºGood<a href="#ref17">[17]</a>ï¼š

> äº‹ä»¶ $F$ æ˜¯äº‹ä»¶ $E$ çš„åŸå› éœ€è¦æ»¡è¶³ï¼š
>
> 1. äº‹ä»¶ $E$ å’Œ $F$ åŒæ—¶æˆç«‹ï¼ˆå¯¹æœ‰æ—¶é—´çº¦æŸçš„äº‹ä»¶åˆ™æ˜¯$F_t \leq E_t$ï¼‰
>
> 2. $P(E|H)<1, P(F|H)<1$ ï¼Œå…¶ä¸­$H$åŒ…å«ä¸¤éƒ¨åˆ†ï¼š
>
>     - $H1$ : æ‰€æœ‰çš„è‡ªç„¶æ³•åˆ™
>
>     - $H2$ : æ‰€æœ‰è¢«è®¤ä¸ºæ˜¯ç†æ‰€å½“ç„¶çš„çœŸå®èƒŒæ™¯æ¡ä»¶
>
> 3. $P(E|FH) > P(E|\bar{F}H)$

Goodåœ¨åç»­çš„ç ”ç©¶<a href="#ref18">[18]</a><a href="#ref19">[19]</a>ä¸­è¯•å›¾ç»™å‡ºå› æœå…³ç³»çš„ä¸€ç§å®šé‡æè¿°ã€‚$F$ å¯¹$E$ çš„æ½œåœ¨å› æœè¶‹åŠ¿å¯ä»¥ç”±ä¸‹å¼åº¦é‡
$$
\log \frac{P(\bar{E}|\bar{F}H)}{P(\bar{E}|FH)}
$$

> where $H$ consists of all laws of nature and the background conditions before $F$ started. Thus for $F$ to be a potential cause of $E$, the **two must be probabilistically dependent conditional on $H$**. The (actual causal) degree to which $F$ caused $E$ is the **limit**, as the sizes of the events tend uniformly to zero, of the strength of the network of causal connections between $E$ and $F$. Here the strength of a link from $F$ to $E$ is measured by the tendency of $F$ to cause $E$; the strength of the network as a whole is a function of these link strengths which takes into account interactions amongst causes.



æ ¹æ®ä»¥ä¸Šæ€è·¯ï¼Œå¯ä»¥åˆ†æå¾—åˆ°ï¼š

- å› æœåœ¨å“²å­¦ä¸Šçš„å®šä¹‰ä¸€èˆ¬éƒ½æ˜¯ç¡®å®šæ€§çš„ï¼Œä½†åœ¨ç°ä»£ç§‘å­¦ä¸­ï¼Œé€šå¸¸è¢«å®šä¹‰ä¸ºæ¦‚ç‡æ€§çš„ã€‚ä¹‹æ‰€ä»¥è¢«å¦‚æ­¤å®šä¹‰ï¼Œä¸€æ–¹é¢æ˜¯æœ‰éƒ¨åˆ†å‰äººçš„å·¥ä½œä¹Ÿå¦‚æ­¤å®šä¹‰ï¼›å¦ä¸€æ–¹é¢ï¼Œç»å…¸çš„æ¦‚ç‡è¶³ä»¥æ¨¡æ‹Ÿäººç±»æ¨ç†çš„å‡ ä¹æ‰€æœ‰æ–¹é¢<a href="#ref15">[15]</a>ã€‚ä»è¿™ä¸ªè§’åº¦ä¸Šæ¥è®²ï¼Œ**æ¦‚ç‡æ€§å› æœæ˜¯å¯¹ç¡®å®šæ€§å› æœçš„ä¸€ä¸ªæ›´å¹¿ä¹‰çš„æè¿°**ã€‚
- ç«™åœ¨æ¦‚ç‡æ€§å› æœçš„è§’åº¦ï¼Œå› æœå‘ç°å¯ä»¥è¢«ç§°ä¹‹ä¸ºï¼Œåœ¨æ•°æ®ä¸­å‘ç°æ¦‚ç‡ç»“æ„çš„å·¥ä½œï¼ˆå³å› ç´ Açš„æ¦‚ç‡åˆ†å¸ƒå˜åŒ–æ—¶ï¼Œå› ç´ Bçš„æ¦‚ç‡åˆ†å¸ƒæ˜¯å¦å˜åŒ–ï¼‰ï¼Œå…¶æœ¬è´¨éƒ½æ˜¯åœ¨æ‹Ÿåˆä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ã€‚ä»è¿™ä¸ªè§’åº¦æ¥è¯´ï¼Œ**æ¦‚ç‡æ¨¡å‹**ä¹Ÿå¯ä»¥ç”¨äºå› æœå‘ç°ã€‚

### å› æœç»“æ„å­¦ä¹ 

è¿‘ä¸‰åå¹´æ¥, å› æœå­¦ä¹ çš„å·¥ä½œä¸€èˆ¬èšç„¦äº"å› æœç»“æ„å­¦ä¹ (casual structure learning)", æ‰€å¾—åˆ°çš„**ç»“æ„å› æœæ¨¡å‹(structural causal model, SCM)** å¯¹å› æœè¿›è¡Œäº†æ¦‚ç‡ã€ç»Ÿè®¡ä¸Šçš„å®šä¹‰ï¼Œå¹¶ç”¨æ°å½“çš„æ¨¡å‹æ¥æè¿°å› æœç»“æ„ã€‚SCMåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†: 

- Graphical models: ç”±å›¾æ¨¡å‹è¡¨ç¤ºçš„å› æœå…³ç³», å…¶ä¸­èŠ‚ç‚¹è¡¨ç¤ºéšæœºå˜é‡, æœ‰å‘è¾¹è¡¨ç¤ºå› æœæ–¹å‘
- Structural equations: åœ¨å›¾æ¨¡å‹ä¸­, æœ‰å‘è¾¹ä¸Šçš„å› æœæ•ˆåº”, ç”±å‡½æ•°å¼è¡¨ç¤º

graphical modelåˆ™æ˜¯structure causal modelçš„ä¸€ç§ï¼Œä¹Ÿæ˜¯å—å¹¿æ³›ç ”ç©¶çš„ä¸€ç§ã€‚

<a href="#ref1">[1]</a>ä¸­å¯¹SCMæœ‰ä»¥ä¸‹è®ºè¿°

> **"structural causal models"** (SCM), which consists of three parts: *graphical models*, *structural equations,* and *counterfactual and interventional logic*. 
>
> Graphical models serve as a language for representing what agents know about the world. Counterfactuals help them articulate what they wish to know. And structural equations serve to tie the two together in a solid semantics.

<a href="#ref3">[3]</a>ä¸­åˆ™ç€é‡æ¨å´‡äº†å›¾æ¨¡å‹ä½œä¸ºå› æœæ¨¡å‹çš„è¡¨è¾¾å½¢å¼

> Methods for extracting causal conclusions from observational studies are on the **middle** rung of Pearlâ€™s Ladder of Causation, and they can be expressed in a mathematical language that extends classical statistics and **emphasizes graphical models**.
>
> Various options exist for causal models: causal diagrams, structural equations, logical statements, and so forth. I am strongly sold on causal diagrams for nearly all applications, primarily due to their transparency but also due to the explicit answers they provide to many of the questions we wish to ask.
>
> â€¦â€¦ 
>
> Pearl defines a causal model to be **a directed acyclic graph** that can be paired with data to produce quantitative causal estimates. The graph embodies the structural relationships that a researcher assumes are driving empirical results. The structure of the graphical model, including the identification of vertices as mediators, confounders, or colliders, can guide experimental design through the identification of minimal sets of control variables. Modern expositions on graphical cause and effect models are Pearl (2009) and Spirtes et al. (2000).

ç»¼ä¸Šæ‰€è¿°ï¼Œcasual discovery / probabilistic model / structure casual model / casual graph ä¹‹é—´çš„å…³ç³»ä¸º

<div align="center">
    <img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img/20221024103453.png" width = "65%" />
</div>
**Remark**: (1) æ ¼å…°æ°å› æœåº”è¯¥å±äºstructure casual modelï¼Œä½†ä¸ä¸€å®šå±äºå›¾æ¨¡å‹ï¼›(2) å›¾æ¨¡å‹ä¸ä»…åŒ…æ‹¬DAGï¼Œè¿˜æœ‰å…¶ä»–ç±»å‹çš„å›¾ã€‚



### å› æœä¸ç»Ÿè®¡æ¨¡å‹çš„å…³è”ä¸åŒºåˆ«

ä¸Šæ–‡ä¸­æåˆ°ï¼Œå¹¿ä¹‰ä¸Šè®²ï¼Œå› æœå­¦ä¹ çš„æœ¬è´¨æ˜¯å­¦ä¹ ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ï¼ˆæ¦‚ç‡æ¨¡å‹å¯ä»¥è¢«è§†ä¸ºç»Ÿè®¡æ¨¡å‹ï¼‰ã€‚ä½†**æ¦‚ç‡æ¨¡å‹ ï¼ˆæˆ–ç»Ÿè®¡æ¨¡å‹ï¼‰ä¸ å› æœ æ˜¯ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„æ¦‚å¿µ**ã€‚

é¦–å…ˆï¼Œæ˜ç¡®ä¸€ä¸ªå…³ç³»ï¼Œå³ï¼šæ ¹æ®å› æœä¸‰é˜¶æ¢¯ï¼Œä»ä¸Šåˆ°ä¸‹åˆ†åˆ«ä¸ºâ€œå…³è”â€â€œå¹²é¢„â€â€œåäº‹å®â€ï¼Œå…¶ä¸­å…³è”æ˜¯ä¸Šè¿°ä¸¤ä¸ªæ¦‚å¿µçš„åŸºç¡€ï¼Œè€Œå¹²é¢„å’Œåäº‹å®æ‰æ˜¯å› æœç‰¹æœ‰çš„å±‚æ¬¡ã€‚<a href="#ref20">[20]</a>å¯¹å…³è”å’Œå› æœç»™å‡ºäº†æ˜ç¡®çš„åˆ†ç•Œçº¿ã€‚

- å…³è”ï¼šå¯ä»¥ç”¨åˆ†å¸ƒå‡½æ•°æ¥å®šä¹‰ï¼Œä¾‹å­ï¼šç›¸å…³æ€§ã€å›å½’ã€ä¾èµ–æ€§ã€æ¡ä»¶ç‹¬ç«‹æ€§ç­‰
- å› æœï¼šä¸èƒ½åªç”¨åˆ†å¸ƒå‡½æ•°æ¥å®šä¹‰ï¼Œä¾‹å­ï¼šå½±å“ã€æ··æ·†ã€å¹²æ‰°ç­‰ã€‚**å› æœä¸èƒ½ä»å…³è”ä¸­æ¨å¯¼å‡º**ï¼Œç”šè‡³**ä¸å¯ä»¥åªä»ç»Ÿè®¡å…³è”çš„è§’åº¦ä¸Šå®šä¹‰**ã€‚

ä»æ•°å­¦çš„è§’åº¦ä¸Šï¼Œä»»ä½•å› æœåˆ†æçš„æ•°å­¦æ–¹æ³•éƒ½**å¿…é¡»è·å¾—æ–°çš„ç¬¦å·**æ¥è¡¨ç¤ºå› æœå…³ç³»ã€‚æ¦‚ç‡ç¬¦å·å¯¹äºè¡¨ç¤ºå› æœå…³ç³»æ¥è¯´æ˜¯ä¸å¤Ÿçš„ã€‚

- ä¸¾ä¾‹æ¥è¯´ï¼Œæ¦‚ç‡ç›¸å…³çš„æ•°å­¦è¯­è¨€ä¸å…è®¸æˆ‘ä»¬è¡¨è¾¾â€œç—‡çŠ¶ä¸å¯¼è‡´ç–¾ç—…â€è¿™ä¸€ç®€å•äº‹å®ï¼Œæ›´ä¸å…è®¸æˆ‘ä»¬ä»è¿™äº›äº‹å®ä¸­å¾—å‡ºæ•°å­¦ç»“è®ºã€‚æˆ‘ä»¬åªèƒ½è¯´ï¼Œä¸¤ä¸ªäº‹ä»¶æ˜¯ç›¸äº’ä¾èµ–çš„â€”â€”è¿™æ„å‘³ç€ï¼Œå¦‚æœæˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªï¼Œæˆ‘ä»¬å°±å¯ä»¥é¢„æœŸé‡åˆ°å¦ä¸€ä¸ªï¼Œä½†æˆ‘ä»¬æ— æ³•**åŒºåˆ†ç»Ÿè®¡ä¾èµ–æ€§**ï¼ˆç”±æ¡ä»¶æ¦‚ç‡ P é‡åŒ–çš„ç–¾ç—…ç—‡çŠ¶ï¼‰å’Œ**å› æœä¾èµ–æ€§**ï¼Œæˆ‘ä»¬åœ¨æ ‡å‡†æ¦‚ç‡æ¼”ç®—ä¸­æ²¡æœ‰å¯¹æ­¤å…³ç³»çš„è¡¨è¾¾å¼<a href="#ref20">[20]</a>ã€‚

è¿™æ˜¯æˆ‘ä»¬ä¸ºå› æœå…³ç³»å»ºç«‹ä¸€å¥—æ–°çš„æ•°å­¦è¡¨è¾¾çš„åŠ¨æœºã€‚

### å› æœåˆ†æä¸­çš„æ•°å­¦è¡¨ç¤º

**Structural Causal Models** 

- Structure Equationsï¼šå˜é‡-ä¸‹æ ‡å½¢å¼ / å¸¦ $do$ æ“ä½œç¬¦çš„å½¢å¼ï¼š
    $$
    ğ‘ƒ(ğ‘Œ_ğ‘¥  = ğ‘¦)âŸºğ‘ƒ(ğ‘Œ=ğ‘¦|ğ‘ ğ‘’ğ‘¡(ğ‘‹=ğ‘¥))âŸºğ‘ƒ(ğ‘Œ=ğ‘¦|ğ‘‘ğ‘œ(ğ‘‹=ğ‘¥))
    $$

    - $P(Y_x = y)$ï¼š$Y$ æ˜¯ä¸€ä¸ªéšæœºå˜é‡ï¼Œå½“éšæœºå˜é‡ $X=x$ æ—¶ $Y$ åœ¨æ€»ä½“ä¸­è¾¾åˆ° $y$ å€¼çš„æ¦‚ç‡ã€‚

    - $P(Y=y|do(X=x))$ï¼šå½“ $X=x$ å‡åŒ€çš„æ–½åŠ åœ¨æ¯ä¸€ä¸ªä¸ªä½“ä¸Šæ—¶ï¼Œ$Y=y$ å‘ç”Ÿçš„æ¦‚ç‡ï¼Œå¸¸ç”¨äºæ§åˆ¶å®éªŒã€‚

- Graphical Modelsï¼šå› æœå‡è®¾ç¼–ç åœ¨**ç¼ºå¤±çš„é“¾æ¥**ä¸­â€”â€”ä¸¤ä¸ªå˜é‡ä¹‹é—´æœ‰è¿æ¥åªä»£è¡¨å­˜åœ¨å› æœå…³ç³»çš„**å¯èƒ½æ€§**ï¼Œè€Œæ²¡æœ‰è¿æ¥åˆ™ä»£è¡¨æ²¡æœ‰å› æœã€‚å¯ä»¥è¾…ä»¥æ–¹ç¨‹å¼æ¥è¡¨è¾¾å› æœä¹‹é—´çš„å®šé‡å…³ç³»ã€‚



**è¡¨è¾¾å› æœæ•ˆåº”å¤§å°**

- $Cov(X, Y)$ï¼šç»™å®šç”±ä»¥ä¸Šæ¨¡å‹è¡¨å¾çš„å› æœå‡è®¾åï¼Œå¯ä»¥ç”¨åæ–¹å·®è¡¨ç¤ºå› æœæ•ˆåº”çš„å¤§å°ï¼Œè¾…åŠ©ä»è§‚å¯Ÿåˆ°çš„éå®éªŒæ•°æ®ä¸­ä¼°è®¡å› æœå‚æ•°ã€‚



**å¹²é¢„â€”â€”æ•°å­¦è¡¨è¾¾**

å¹²é¢„çš„åŸºç¡€æ˜¯ç»“æ„æ–¹ç¨‹ï¼ˆSEMï¼‰ï¼Œå¹¶é€šè¿‡$do$è¿ç®—ç¬¦å®Œæˆã€‚

- $do(x)$ï¼šæ¨¡æ‹Ÿäº†ä¸€ç§ç‰©ç†ä¸–ç•Œçš„äº¤äº’â€”â€”åœ¨ç»™å®šçš„SEMä¸­ï¼Œ**åˆ é™¤**åŸæ¨¡å‹ä¸­Xå˜é‡çš„å‡½æ•°ï¼Œå¹¶äººä¸º**æ›¿æ¢**å˜é‡ä¸ºä¸€ä¸ªå¸¸æ•° $X=x$ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º
    - $P(z, y | do(x))$ï¼šå˜é‡ $Y$ å’Œ $Z$ çš„å¹²é¢„ååˆ†å¸ƒï¼Œå³è¡¨ç¤ºå¯¹æ‰€æœ‰ä¸ªä½“å‡å®æ–½äº†$X=x$ åï¼Œå˜é‡ $Y$ å’Œ $Z$ çš„è”åˆåˆ†å¸ƒ
    - $P(z, y, x)$ï¼šå˜é‡çš„å¹²é¢„å‰åˆ†å¸ƒ
- è®°å¹²é¢„å‰çš„å› æœæ¨¡å‹ä¸º$M$ï¼Œå¹²é¢„ $X=x$ åçš„å› æœæ¨¡å‹ä¸º$M_x$
    - $P_M (y|do(x)) â‰œ P_{M_x}(y)$ï¼šåœ¨å¹²é¢„å‰çš„æ¨¡å‹ $M$ ä¸­å®æ–½å¹²é¢„ $do(x)$ å $Y$ çš„åˆ†å¸ƒï¼Œç­‰ä»·äºåœ¨å¹²é¢„åæ¨¡å‹ $M_x$ ä¸­$ Y$ çš„åˆ†å¸ƒã€‚

<img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img/image-20221117170455716.png" alt="image-20221117170455716" style="zoom:50%;" />

å¹²é¢„çš„æ•ˆæœè¡¨ç¤º

- Causal effectï¼š$P(Y=y|do(x))= \sum_z P(z, y|do(x))$
- Measurements
    - Average Differenceï¼š$E(Y|do(x_0^{'})) -E(Y|do(x_0))$
    - Experimental Risk Ratioï¼š$\frac{E(Y|do(x_0^â€²))}{E(Y|do(x_0))}$



**åäº‹å®â€”â€”æ•°å­¦è¡¨è¾¾**

- $Y_x (u)$ï¼šåœ¨å˜é‡æ›¾è¢«è®¾ç½®ï¼ˆhas been setï¼‰ä¸º $X=x$ çš„æƒ…å†µä¸‹ï¼Œä¸ªä½“ $u$ å¾—åˆ°çš„ $Y$ å˜é‡çš„å€¼
- $Y_x (u)â‰œY_{M_x} (u)$ï¼šUnit-levelçš„åäº‹å®ï¼Œå®šä¹‰ä¸ºåœ¨å¹²é¢„åæ¨¡å‹ $M_x$ ä¸­ï¼Œä¸ªä½“ $u$ å¾—åˆ°çš„ $Y$ å˜é‡çš„å€¼ã€‚
    - åäº‹å®å¯ä»¥è¢«è§†ä¸ºç‰¹å®šæƒ…å¢ƒå› ç´ ï¼ˆä¸è¿‡å»æŸä¸ªæ—¶é—´çš„æ‰€æœ‰å› ç´ ä¸€è‡´ï¼‰ä¸‹çš„å¹²é¢„ã€‚
    - åäº‹å®ä¸€èˆ¬ç ”ç©¶ç‰¹å®šæƒ…å¢ƒå› ç´ ä¸‹ï¼Œä¸ªä½“çš„å¹²é¢„ç»“æœã€‚å¹²é¢„åˆ™ä¸€èˆ¬ç ”ç©¶å†³ç­–çš„**å¹³å‡**å½±å“æƒ…å†µ



### åäº‹å®æ¨ç†

ä»ä¸Šæ–‡å¯ä»¥çœ‹å‡ºï¼Œå› æœåŒºåˆ«ä¸ä¸€èˆ¬çš„ç»Ÿè®¡æ¨¡å‹ï¼Œå…¶ä¸­å¹²é¢„å’Œåäº‹å®èµ·åˆ°äº†å†³å®šæ€§çš„ä½œç”¨ã€‚æœ¬èŠ‚å°†å…ˆåŒºåˆ«å¹²é¢„ä¸åäº‹å®çš„åŒºåˆ«ï¼Œç„¶åé˜è¿°åäº‹å®æ¨ç†çš„åŸºæœ¬æ­¥éª¤ã€‚

ä»ç›®æ ‡çš„è§’åº¦

- å¹²é¢„ï¼šå›ç­”â€œå¦‚æœ**ç°åœ¨**å¹²é¢„å˜é‡Xï¼Œé‚£ä¹ˆå¯¹Zä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ï¼Ÿâ€
- åäº‹å®ï¼šå›ç­”â€œå¦‚æœåœ¨**è¿‡å»æŸä¸ªæ—¶é—´**å¹²é¢„å˜é‡Xï¼ŒZä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ï¼Ÿâ€

å…¶åŒºåˆ«åœ¨äº

- â€œå¹²é¢„â€æ”¹å˜ä½†ä¸ä¸è§‚å¯Ÿåˆ°çš„ä¸–ç•Œç›¸çŸ›ç›¾ï¼Œå› ä¸ºå¹²é¢„å‰åçš„ä¸–ç•Œå¤„äºä¸åŒçš„æ—¶é—´

- â€œåäº‹å®â€åˆ™ä¸å·²çŸ¥äº‹å®ç›¸å†²çª

æ³¨ï¼šäºŒè€…å¹¶ä¸æ˜¯è¢«ä¸¥æ ¼åŒºåˆ†çš„ï¼Œä¹Ÿæœ‰ç ”ç©¶ä¸åŒºåˆ†äºŒè€…ï¼Œè¿™æ˜¯ä¸€ç§å“²å­¦/æ–‡åŒ–ä¸Šçš„å·®åˆ«



**åäº‹å®æ¨ç†çš„åŸºæœ¬æ­¥éª¤**

**Background**ï¼šSCMåŠå…¶å½“ä¸­çš„å‚æ•°

1. Step1: å¤–å±•â€”â€”ä¸ºæ¯ä¸ªè§‚æµ‹å˜é‡è®¾ç½®ä¸€ä¸ªåœ¨**è¿‡å»å¯èƒ½æœªè§‚æµ‹**åˆ°çš„å˜é‡é›†åˆ$U$ï¼ŒåŸºäºå†å²è§‚æµ‹å­¦ä¹ é›†åˆ$U$

2. Step2: å¹²é¢„â€”â€”ä¸ºåäº‹å®æ¨ç†å»ºç«‹æ–°çš„å¹²é¢„æ¨¡å‹ï¼Œå…¶ä¸­å¹²é¢„æ“ä½œå°†ä¼šä»£æ›¿SCMä¸­çš„ä¸€ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰å˜é‡

3. Step3: é¢„æµ‹â€”â€”å°†å†å²æœªè§‚æµ‹å˜é‡$U$ä»¥åŠ**å¹²é¢„æ“ä½œ**ä»£å…¥ä¿®æ”¹åçš„SCMï¼Œè¿›è¡Œåäº‹å®æ¨ç†

<img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img/image-20221117171058267.png" alt="image-20221117171058267" style="zoom:67%;" />

**åäº‹å®ï¼ˆCounterfactualï¼‰æ¨ç†â€”â€”ä»¥ç¡®å®šæ€§æ¨¡å‹ä¸ºä¾‹**

![image-20221117171259748](https://raw.githubusercontent.com/KMdsy/figurebed/master/img/image-20221117171259748.png)

å¯¹äºæ¦‚ç‡å‹æ¨¡å‹ï¼Œåˆ™éœ€è¦é’ˆå¯¹å˜é‡çš„æ‰€æœ‰æƒ…å†µè¿›è¡Œè€ƒè™‘ã€‚å…¶ä¸­â€œé¢„æµ‹â€åˆ™ç”±â€œæ±‚æ¦‚ç‡â€è½¬ä¸ºâ€œæ±‚æœŸæœ›â€ã€‚

ä¸‹é¢çš„æŒ‡æ ‡å¯ä»¥ç”¨äº**è¯„ä¼°**æŸä¸ªæ“ä½œæ˜¯å¦å¯¹æœªæ¥æœ‰å½±å“<a href="#ref20">[20]</a>ï¼Œæ­¤å¤–è¿˜æœ‰å¤šç§æŒ‡æ ‡ï¼Œå¦‚
$$
P N(x, y)=P\left(Y_{x^{\prime}}=y^{\prime} \mid X=x, Y=y\right) \\
E T T=P\left(Y_x=y \mid X=x^{\prime}\right)
$$

### æ”¯æ’‘ææ–™

â€œç»“æ„å­¦ä¹ æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ¨¡å‹é€‰æ‹©é—®é¢˜ï¼Œé€‰æ‹©ä¸€ä¸ªç»™å®šæ•°æ®é›†ä¸Šæœ€èƒ½å¤Ÿæè¿°æ•°æ®ä¾èµ–çš„æ¨¡å‹ã€‚å› æœç»“æ„å­¦ä¹ æ˜¯ç»“æ„å­¦ä¹ ä¸­çš„ä¸€ç§ç‰¹ä¾‹ï¼Œå…¶å­¦ä¹ äº†ä¸€ä¸ªå› æœå›¾â€ã€‚è¿™ä¸ªè§‚ç‚¹æ˜¯è¢«æ™®éæ¥å—çš„ã€‚

**Remark**ï¼šç»“æ„å­¦ä¹ çš„ä¸‰ç§æ–¹æ³•ï¼ˆåŸºäºçº¦æŸã€åŸºäºåˆ†æ•°ã€åŸºäºå‡½æ•°ï¼‰æœ¬è´¨ä¸Šéƒ½å¯ä»¥ç»†åˆ†ä¸ºé€šè¿‡ç»„åˆ/æœç´¢ç®—æ³•ï¼Œæ¥è¯†åˆ«å› æœç»“æ„ <a href="#ref13">[13]</a>

> **Structure learning is a model selection problem** in which one estimates or learns a graph that best describes the dependence structure in a given data set (Drton & Maathuis 2017). **Causal structure learning is the special case** in which one tries to learn the **causal graph** or certain aspects of it, and this is what we focus on in this article.
>
> â€”â€” Heinze-Deml, C., Maathuis, M. H., & Meinshausen, N. (2018). Causal structure learning. *Annual Review of Statistics and Its Application*, *5*, 371-391.

**Q1ï¼šé™¤DAGå¤–ï¼Œè¿˜æœ‰å“ªäº›å› æœå›¾** 

æ‘˜è‡ª <a href="#ref13">[13]</a>

> Other types of graph used to represent causal structure include Partially Oriented Induced Path Graphs (POIPGs)[190, 228], SingleWorld Intervention Graphs (SWIGs) [24, 201, 202], Ïƒ-connection graphs [56], undirected graphs[11], interaction and component graphs for dynamic systems [40], Maximal Almost Ancestral Graphs (MAAGs)[231], psi-ECs [110], Patterns [274], and arid, bow-free, and ancestral ADMGs [19]. 
>
> There are also other types of assumptions relating to the functional form of the structural relationships (e.g., linear or non-linear) as well as the parametric form of the marginals and the errors (e.g., Gaussian or non-Gaussian).

**Q2ï¼šå¤§æ•°æ®å¯¹å› æœå‘ç°çš„è´¡çŒ®**

ç”±ä¸‰é˜¶æ¢¯å®šä¹‰çš„å› æœé€šå¸¸æ˜¯éš¾ä»¥æ¨æ–­çš„ï¼Œå› ä¸ºå¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå®éªŒäººå‘˜éƒ½éš¾ä»¥â€œå¹²é¢„â€ï¼Œæ›´åˆ«è¯´â€œåäº‹å®â€ã€‚æ­¤å¤–ï¼Œå¯èƒ½å­˜åœ¨â€œæœªè¢«è§‚æµ‹çš„æ½œåœ¨å› ç´ â€ã€â€œå› æœçŸ¥è¯†é€šå¸¸æ˜¯éå…ˆéªŒçš„ï¼ˆæˆ‘ç†è§£æ˜¯ï¼Œéå…ˆéªŒå¯¼è‡´éš¾ä»¥åäº‹å®ï¼‰â€ä¹Ÿæ˜¯é˜»ç¢å› æœå‘ç°ä¸ä¼°è®¡çš„å› ç´ ä¹‹ä¸€ <a href="#ref13">[13]</a>ã€‚

> Unfortunately, in many cases, it may not be possible to undertake such experiments due to prohibitive cost, ethical concerns, or impracticality. For example, to understand the impact of smoking, it would be necessary to force diferent individuals to smoke or not-smoke. **Researchers are therefore often left with non-experimental, observational data.** In the absence of intervention and manipulation, observational data leave researchers facing a number of challenges: Firstly, observational datasets may not contain all relevant variables - **there may exist unobserved/hidden/latent factors** (this is sometimes referred to as the third variable problem). Secondly, observational data may **exhibit selection bias** - for example, younger patients may in general prefer to opt for surgery, whereas older patients may prefer medication. Thirdly, the causal **relationships underlying these data may not be known a priori** - for example, are genetic factors independent causes of a particular outcome, or do they mediate or moderate an outcome? These three challenges afect the discovery and estimation of causal relationships

å› æ­¤ï¼Œå¤§æ•°æ®ã€æˆ–æœºå™¨å­¦ä¹ ç®—æ³•åœ¨å› æœå‘ç°é—®é¢˜ä¸­æ‰®æ¼”çš„è§’è‰²å¯ä»¥æè¿°ä¸º

- å¤§æ•°æ®çš„æ•°æ®é‡çº§å¼¥è¡¥äº†è§‚å¯Ÿä¸å……åˆ†å¯¼è‡´çš„â€œæœªè§‚å¯Ÿã€æ¼è§‚å¯Ÿâ€ã€â€œé€‰æ‹©åå·®â€ï¼Œå³å¤§æ•°æ®ä½¿å¾—æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°æ›´å¤šçš„å˜é‡ï¼Œå½“è§‚å¯Ÿè¶³å¤Ÿå……åˆ†æ—¶ï¼Œæ¨æ–­å‡ºçœŸå®å› æœçš„æ¦‚ç‡å°±è¶Šå¤§ã€‚
- å¤§æ•°æ®ä¹Ÿå¯ä»¥ä»¥æ•°æ®é‡çº§å‡è½»é€‰æ‹©åå·®ï¼ˆæˆ‘ç†è§£æ˜¯ï¼šè™½ç„¶å¹´è½»äººå¯èƒ½æ›´å€¾å‘äºé€‰æ‹©æ•´å½¢æ‰‹æœ¯ï¼Œä½†éšç€æ ·æœ¬å¢å¤šï¼Œä¹Ÿå¯ä»¥æ‰¾åˆ°å€¾å‘äºåšæ•´å½¢æ‰‹æœ¯çš„è€å¹´äººï¼‰ã€‚
- å¤§æ•°æ®å¯èƒ½å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¿›è¡Œåäº‹å®ï¼Œä¾‹å¦‚å¯¹äºä¸€ä¸ªå‘¨æœŸç³»ç»Ÿï¼Œé€šè¿‡è¶³å¤Ÿå¤šå‘¨æœŸçš„è§‚å¯Ÿï¼Œæˆ‘ä»¬ä¹Ÿè®¸å¯ä»¥æ‰¾åˆ°ä¸€ä¸ªæ—¶é—´ç‚¹ï¼Œåªæœ‰ä¸€ä¸ªåŸå› å˜é‡å‘ç”Ÿå˜åŒ–ï¼Œè€Œå…¶ä»–æ‰€æœ‰å˜é‡éƒ½ä¸å†å²ä¿æŒä¸€è‡´ï¼Œè¿™ç§åœºæ™¯æœ‰åˆ©äºæ¨æ–­å› æœåäº‹å®ã€‚

æ­¤å¤–ï¼Œå¯¹æ¯”å®éªŒæ•°æ®ï¼ˆå³å­˜åœ¨â€œå¹²é¢„-æ•ˆæœâ€ç»“æ„çš„æ•°æ®ï¼‰ä»¥åŠè§‚æµ‹æ•°æ®ï¼ˆå³åªåŒ…å«éä¸»åŠ¨å¹²é¢„ä»¥åŠè¢«åŠ¨è§‚æµ‹çš„æ•°æ®ï¼‰ï¼Œè§‚æµ‹æ•°æ®å¯ä»¥æä¾›æ›´å¥½çš„ç»Ÿè®¡èƒ½åŠ›å’Œå¯æ¨å¹¿æ€§ <a href="#ref13">[13]</a>ã€‚



## Casual Structure Learning

### Casual structure learningçš„ä¸‰ç±»æ–¹æ³•

Casual structure learningçš„ç»å…¸åˆ†ç±»æ–¹æ³•å¯åˆ†ä¸ºä¸‰ä¸ª**ä¸»è¦ç±»åˆ«**ï¼šconstrain-based, score-based, functional casual model <a href="#ref2">[2]</a>ï¼Œè¿˜æœ‰ä¸€äº›hybird methodï¼Œæ­¤å¤„ä¸åˆ—å‡ºã€‚

**Remark**ï¼šä¹Ÿæœ‰æ–‡ç« <a href="#ref13">[13]</a>æå‡ºâ€œconstraint-based, score-based, those exploiting structural asymmetries, and those exploiting various forms of interventionâ€çš„åˆ†ç±»æ–¹æ³•ï¼Œè¿™ç§åˆ†ç±»æ–¹æ³•æ¯”è¾ƒæ–°ï¼Œå¯èƒ½å¯¹è¿‘æœŸï¼ˆ2022ï¼‰å·¥ä½œæœ‰è¾ƒå¥½çš„é€‚åº”æ€§ã€‚

- **Constraint-based methods**: è¿™ç±»æ–¹æ³•ä¾èµ–éšæœºå˜é‡é—´çš„**æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•(conditional independency test)** æ¢ç©¶å˜é‡é—´çš„å› æœç»“æ„

    - åœ¨ä¼ ç»Ÿçš„PCç®—æ³•ä¸­, ä¸ºäº†ç®€ä¾¿çš„æ¨å¯¼å‡ºå› æœç»“æœ, åŸºäºCIå®šä¹‰äº†ä¸¤ç§å›¾ä¸Šçš„ç»“æ„, å³ V-structure / D-separation, è¿™ä¸¤ç§ç»“æ„å¯ä»¥è¾…åŠ©æ¨å¯¼å‡ºå› æœçš„ç»“æ„ä¸æ–¹å‘ã€‚å…·ä½“çš„, PCé¦–å…ˆæ„é€ ä¸€ä¸ªå®Œå…¨å›¾, ç„¶åé€šè¿‡ä¸¤ä¸¤å˜é‡é—´çš„independency teståˆ é™¤æŸäº›æ— å‘è¾¹, ç„¶ååŸºäºCI testä»¥åŠV-structure / D-separation, ç¡®å®šå…¶ä½™è¾¹çš„æ–¹å‘æˆ–åˆ é™¤æŸäº›è¾¹ã€‚

    - ç¼ºç‚¹: 

        1. ä¸èƒ½å­˜åœ¨æœªè§‚æµ‹çš„æ··æ‚å˜é‡, è¯¥æ¡ä»¶åœ¨å¤§æ•°æ®çš„æƒ…å†µä¸‹å¾ˆéš¾æ»¡è¶³, ä½†å­˜åœ¨å¦‚FCIçš„ç®—æ³•æ”¾å®½äº†è¯¥é™åˆ¶
        2. æ ¹æ®å› æœä¿¡å¿µå‡è®¾, åªèƒ½æ ¹æ®æ¡ä»¶ç‹¬ç«‹æ€§æ¥åˆ¤æ–­å› æœå…³ç³», å› æ­¤éœ€è¦éå¸¸å¤šä¸”é«˜è´¨é‡çš„æ•°æ®, å¦‚æœæ•°æ®è¾ƒå°‘, åˆ™æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾æµ‹è¯•å¯èƒ½ä¼šäº’æ–¥
        3. å¯¹äºåˆ†å‰ç»“æ„ä»¥åŠå¯¹æ’ç»“æ„, è¯¥ç±»ç®—æ³•æ— æ³•æ ¹æ®æ¡ä»¶ç‹¬ç«‹æ€§åˆ†è¾¨**é©¬å°”å¯å¤«ç­‰ä»·ç±»(Markov equivalent class)**, å› æ­¤å¯¹å±€éƒ¨å› æœå…³ç³»çš„åˆ¤åˆ«ä¸è¶³

        - **Markov equivalent class**: æ‹¥æœ‰ç›¸åŒdåˆ†ç¦»ç»“æ„çš„å› æœå›¾å¹¶ä¸”å…·æœ‰ç›¸åŒæ¡ä»¶ç‹¬ç«‹æ€§å…³ç³»çš„å› æœå›¾è¢«ç§°ä½œé©¬å°”å¯å¤«ç­‰ä»·ç±», æ— æ³•æ ¹æ®æ¡ä»¶ç‹¬ç«‹æ€§åˆ†è¾¨å› æœæ–¹å‘ã€‚

- **Score-based methods**: è¿™ç±»æ–¹æ³•é¦–å…ˆæŒ‡å®šå› æœçˆ¶èŠ‚ç‚¹åˆ°å­èŠ‚ç‚¹ä¹‹é—´çš„å‡½æ•°å…³ç³», ç„¶åä»¥æŸä¸ªåˆ†æ•°, å¦‚AIC / BIC, ä¸ºä¼˜åŒ–ç›®æ ‡, ä¼˜åŒ–å¾—åˆ°**å›¾ç»“æ„**ä»¥åŠç›¸å…³å‚æ•°ã€‚

    - å¦‚NOTEARSå‡è®¾å‡½æ•°å…³ç³»ä¸º $x=\sum w_x f(P_a(x))$ , å…¶ä¸­ $w_x$ æ˜¯å˜é‡ $x$ çš„æƒé‡, $P_a(x)$ æ˜¯å…¶å› æœçˆ¶èŠ‚ç‚¹
    - ç¼ºç‚¹: 
        1. è¯¥æ–¹æ³•ä¹Ÿä¼šå¾—åˆ°é©¬å°”å¯å¤«ç­‰ä»·ç±»ã€‚
        2. ç”±äºè¦æ‰¾åˆ°æœ€ä¼˜åˆ†æ•°, å°±è¦æœç´¢å…¨éƒ¨çš„å›¾, è¿™æ˜¯ä¸€ä¸ªNP-hardçš„é—®é¢˜, å¤æ‚åº¦æé«˜ä¸”å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

- **Functional casual model**: è¿™ç±»æ–¹æ³•å¾€å¾€æ¢ç©¶ä¸¤ä¸ªå·²æœ‰å…³è”çš„å˜é‡ä¹‹é—´çš„å› æœæ–¹å‘ã€‚é¦–å…ˆå¯¹æ•°æ®ä¸å› æœå‡½æ•°åšå‡ºå‡è®¾, ç„¶åé€šè¿‡æµ‹è¯•ä¸¤ä¸ªå˜é‡ä¹‹é—´æ˜¯å¦æ»¡è¶³å…³è”å‡½æ•°, æ¥åˆ¤æ–­äºŒè€…ä¹‹é—´çš„å…³è”æ–¹å‘ã€‚

    - å¦‚LiNGAMå‡è®¾å› æœä¹‹é—´æ»¡è¶³**çº¿æ€§å…³ç³»**, ä¸”æ•°æ®ä¸­çš„å™ªéŸ³ä¸º**é«˜æ–¯å™ªå£°**

    - è¯¥ç±»æ–¹æ³•ç”±äºè¿›è¡Œäº†ä¸¥æ ¼çš„å‡è®¾, ä¸”ä¸€èˆ¬ä¼šæ ¹æ®å‡½æ•°çš„æ‹Ÿåˆç¨‹åº¦æ¥æ‰¾åˆ°å”¯ä¸€çš„å› æœæ–¹å‘, å› æ­¤ä¸€èˆ¬ä¸ä¼šå‡ºç°é©¬å°”å¯å¤«ç­‰ä»·ç±»

    - æ³¨æ„, FCMä¸€èˆ¬æ˜¯æ¢ç©¶ä¸¤ä¸ªå˜é‡ä¹‹é—´å› æœå…³ç³»çš„æ–¹æ³•, å¦‚<a href="#ref4">[4]</a>æ‰€è¿°ã€‚è¯¥ç±»æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å¯¹æ•°æ®ç‰¹æ€§ä»¥åŠå› æœæœ‰è¾ƒå¼ºçš„å‡è®¾ã€‚

        > Determining causal relationships **between two variables** is a fundamental and challenging causal discovery task (Janzing et al., 2012). **Conventional constraint-based and score-based causal discovery methods identify causal structures only up to Markov equivalent classes (Spirtes et al., 2001), in which some causal relationships are undetermined.** To address this challenge, properly constrained functional causal models (**FCMs**) have been proposed. FCMs represent the effect as a function of its cause and independent noise and can help identify the causal direction between two variables by imposing substantial structural constraints on model classes, such as additive noise models (ANMs)

<div align="center">
    <img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img/image-20221018113112863.png" width = "75%" />
</div>


**éœ€è¦æŒ‡å‡ºçš„æ˜¯: å›¾æ¨¡å‹åªæ˜¯ä¸€ç§å› æœå…³ç³»çš„è¡¨ç¤ºæ–¹å¼, ä½†è¯¥è¡¨ç¤ºæ–¹å¼ä¸æ˜¯å¿…è¦çš„ã€‚**

ä¸Šè¿°ä¸‰ç±»æ–¹æ³•, ç”±äºå…¶å‡è®¾ä¸åŒã€æ£€éªŒæ–¹æ³•ä¸åŒ, å› æ­¤æŒ–æ˜å‡ºçš„"å› æœ"å…·æœ‰ä¸åŒå«ä¹‰(å³å› æœå›¾ä¸­çš„æœ‰å‘è¾¹å…·æœ‰ä¸åŒçš„å«ä¹‰), åˆ†å±ä¸åŒçš„å› æœé˜¶æ¢¯: 

- Constraint-based: è¯¥ç±»æ–¹æ³•é€šè¿‡ä¸€ç³»åˆ—å˜é‡ä¹‹é—´çš„CI, å­¦ä¹ å˜é‡ä¹‹é—´çš„å› æœå…³ç³»ã€‚ è¯¥ç±»æ–¹æ³•æŒ–æ˜å‡ºçš„å› æœæœ¬è´¨æ˜¯"**æ¡ä»¶ä¾èµ–**", è¿™ç±»ä¾èµ–å±äº"**å…³è”**"å±‚é¢ã€‚
- Score-based / Functional causal model: è¯¥ç±»æ–¹æ³•é¦–å…ˆå®šä¹‰äº†å› æœå˜é‡ä¹‹é—´æ»¡è¶³çš„**å‡½æ•°å…³ç³»**, å‰è€…ä¼˜åŒ–å…¨å±€å¾—åˆ†å‡½æ•°æ¥ç¡®å®šå˜é‡é—´çš„å› æœ, åè€…é‡‡ç”¨ç©·ä¸¾ä¼˜åŒ–ç®—æ³•æœç´¢å˜é‡é—´çš„å› æœã€‚è¿™ä¸¤ç±»æ–¹æ³•æŒ–æ˜å‡ºçš„å› æœæœ¬è´¨æ˜¯ç”±"å›å½’å…³ç³»"è¡¨ç¤ºçš„"å…³è”"ã€‚

**Q3ï¼šCDä¸RCAçš„å…³ç³»**

æ­¤å¤–, å¼ºè°ƒä¸€ä¸‹Root Cause Analysis(RCA)ä¸CDçš„å…³ç³», å³: ä¸€èˆ¬çš„RCAæ›´å…³æ³¨Causal discoveryçš„å‰ä¸¤ä¸ªç­‰çº§, å³æ¢ç©¶"ä»€ä¹ˆå’Œå¼‚å¸¸ç›¸å…³ï¼Ÿ""ä»€ä¹ˆå¯¼è‡´äº†å¼‚å¸¸ï¼Ÿ", è¿™å°±æ˜¯ä¸ºä½•è®¸å¤šRCAçš„æ–¹æ³•éƒ½**åªè€ƒè™‘äº†å…³è”ã€æ¨ç†**, å› æ­¤Causal discoveryå’ŒRCAçš„å…³ç³»å¦‚ä¸‹: 

<div align="center">
	<img src="https://raw.githubusercontent.com/KMdsy/figurebed/master/img/image-20221018113441012.png" width = "33%" />
</div>


### ä»ä¼˜åŒ–çš„è§’åº¦åˆ†æä¸‰ç±»æ–¹æ³•

ä¸ºäº†ç†è§£ä¸‰ç±»Casual structure learningçš„æ–¹æ³•, è¿™é‡Œä»ä¼˜åŒ–çš„è§’åº¦å¯¹ä¸‰ç±»æ–¹æ³•è¿›è¡Œé˜è¿°ã€‚

é¦–å…ˆç”¨$\mathcal{G}$è¡¨ç¤º$d$ä¸ªèŠ‚ç‚¹æ‰€æ„æˆçš„æœ‰å‘å›¾ç©ºé—´ã€‚å¯¹ $\forall G(\boldsymbol{M}) \in \mathcal{G}$ , ç”¨ $\boldsymbol{M}$ è¡¨ç¤ºå¯¹åº”çš„é‚»æ¥çŸ©é˜µ, åè¿‡æ¥, ç”¨ $G(\boldsymbol{M})$ è¡¨ç¤ºä»¥ $\boldsymbol{M}$ ä¸ºé‚»æ¥çŸ©é˜µçš„æœ‰å‘å›¾ã€‚å…ƒç´  $M_{i,j}=1$ è¡¨ç¤ºå­˜åœ¨å› æœå…³ç³» $\boldsymbol{x}_i \rightarrow \boldsymbol{x}_j$ ï¼Œ$M_{i,j}=0$ è¡¨ç¤ºä¸å­˜åœ¨å› æœå…³ç³»ã€‚ $\boldsymbol{X}=[\boldsymbol{x}_1, \cdots, \boldsymbol{x}_d] \in \mathbb{R}^{n \times d}$ è¡¨ç¤º $d$ ç»´çš„è§‚æµ‹æ•°æ®, å…¶ä¸­æ¯ä¸ªæ•°æ®è§‚æµ‹ $n$ æ¬¡ã€‚$\mathbb{D}$ è¡¨ç¤ºç”± $d$ ä¸ªèŠ‚ç‚¹ç»„æˆçš„æœ‰å‘æ— ç¯å›¾é›†åˆã€‚

### Constraint-based Method

åŸºäºçº¦æŸçš„ç®—æ³•åˆ©ç”¨ ä»ä¸€ç³»åˆ—ç»Ÿè®¡æµ‹è¯•ä¸­è·å¾—çš„ä¸€ç»„æ¡ä»¶ç‹¬ç«‹æ€§ç»“æœ æ¥æ¢å¤å› æœå›¾ã€‚

å½“ä»æ•°æ® $\boldsymbol{X}$ ä¸­å·²ç»å­¦ä¹ åˆ°æ¯ä¸€å¯¹å˜é‡é—´æ¡ä»¶ç‹¬ç«‹æ£€éªŒçš„æœ€å°æµ‹è¯•ç»Ÿè®¡é‡ï¼Œå¦‚p-valueï¼Œå› æ­¤å¯ä»¥æ„é€ å‡ºæµ‹è¯•ç»Ÿè®¡é‡çŸ©é˜µ $\boldsymbol{P}$ ï¼Œå…¶ä¸­å¯¹è§’çº¿ä¸Šçš„å…ƒç´ å‡ä¸º0ï¼Œå…ƒç´  $P_{i,j}$ è¡¨ç¤º $\boldsymbol{x}_i , \boldsymbol{x}_j$ é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§æ£€éªŒçš„æµ‹è¯•ç»Ÿè®¡é‡ï¼Œå‡è®¾æ£€éªŒçš„æ˜¾è‘—æ€§æ°´å¹³ä¸º $\alpha$ ã€‚ $f$ è¡¨ç¤ºæ¡ä»¶ç‹¬ç«‹æ£€éªŒç»Ÿè®¡é‡çš„å‡½æ•°ï¼Œ $Q$ è¡¨ç¤ºç”¨äºè¯„ä»·å¾—åˆ°çš„ç»Ÿè®¡é‡çŸ©é˜µä¸å›¾ $G$ çš„æ‹Ÿåˆç¨‹åº¦çš„å‡½æ•°ã€‚

è¯¥ç±»æ–¹æ³•çš„ä¼˜åŒ–é—®é¢˜è¡¨è¿°ä¸º: 
$$
\begin{array}{}
\min : & Q(\boldsymbol{M}, f(\boldsymbol{P}, \alpha)) \\
s.t. & G(\boldsymbol{M}) \in \mathbb{D} \\
var: & \boldsymbol{M} \in\{0,1\}^{d \times d} \\
\end{array}
$$
**ä¸¾ä¾‹**: å¦‚åœ¨PC<a href="#ref5">[5]</a>ç®—æ³•ä¸­ï¼Œå­˜åœ¨å‡è®¾æ£€éªŒ $\left\{\begin{array}{}
H_0: & \boldsymbol{x}_i \perp \boldsymbol{x}_j \\
H_1: & \boldsymbol{x}_i \perp / \boldsymbol{x}_j
\end{array}\right.$ ï¼Œå½“æµ‹è¯•ç»Ÿè®¡é‡å°äºæ˜¾è‘—æ€§æ°´å¹³æ—¶ï¼Œ $H_1$ æˆç«‹ï¼Œå³æœ‰
$$
Q(\boldsymbol{M}, f(\boldsymbol{P}, \alpha))=\sum_{i, j=1: \mathrm{d}} M_{i, j} \cdot\left(P_{i, j}-\alpha\right)
$$
è¡¨ç¤ºä»æ•°æ®ä¸­å¾—åˆ°çš„(æ¡ä»¶)ç‹¬ç«‹çº¦æŸåœ¨å›¾å¾—åˆ°çš„(æ¡ä»¶)ç‹¬ç«‹çº¦æŸé›†åˆä¸­æœªå‡ºç°çš„æ•°é‡ã€‚

### Score-based Method

åŸºäºå¾—åˆ†çš„ç®—æ³•æœ€å¤§åŒ–å›¾ $G$ ä¸è§‚æµ‹æ•°æ® $\boldsymbol{X}$ ä¹‹é—´çš„é€‚åº”åº¦, æ¥æ„å»ºå› æœç»“æ„ã€‚è¯¥ç±»æ–¹æ³•çš„ä¼˜åŒ–é—®é¢˜è¡¨è¿°ä¸º: 

$$
\begin{array}{ll}\max &S\left( \boldsymbol{M} ,\boldsymbol{X} \right)  \\ \text{s.t.} &G\left( \boldsymbol{M} \right)  \in \mathbb{D} \\ \text{var} &\boldsymbol{M} \in \left\{ 0,1\right\}^{d\times d}  \end{array}
$$
å…¶ä¸­DAGçº¦æŸåœ¨<a href="#ref6">[6]</a>ä¸­è¢«é‡å†™ä¸º $\text{tr} \left( {}e^{\boldsymbol{M} \circ \boldsymbol{M} }\right)  -d=0$ , è¿™ä½¿å¾—ç›®æ ‡å‡½æ•°å¯ä»¥è¢«è¿ç»­ä¼˜åŒ–ã€‚$S(\cdot)$ä¸ºå›¾ä¸è§‚æµ‹åŠ©å±€ä¹‹é—´çš„é€‚åº”åº¦å¾—åˆ†, å¯ç”¨çš„å¾—åˆ†å‡½æ•°åŒ…æ‹¬BIC(GES<a href="#ref7">[7]</a>)ã€Bde<a href="#ref8">[8]</a>ã€Bge<a href="#ref9">[9]</a>ã€‚ä¸åŒçš„æ–¹æ³•å¾€å¾€é‡‡ç”¨ä¸åŒçš„æœç´¢ç®—æ³•åœ¨å›¾ç©ºé—´ä¸­ä¸å“¦è¯ä¸Šè¿°ç›®æ ‡å‡½æ•°, å¦‚: è´ªå¿ƒæœç´¢(greedy search)<a href="#ref8">[8]</a>ã€é¡ºåºæŸ¥æ‰¾(order search)<a href="#ref10">[10]</a>ã€åæ ‡ä¸‹é™<a href="#ref5">[5]</a>ã€‚

**ä¸¾ä¾‹**: NOTEARS<a href="#ref11">[11]]</a>ä¸­çš„å¾—åˆ†å‡½æ•°ä¸º
$$
\mathcal{S}(\boldsymbol{M}, \boldsymbol{X})=\frac{1}{2 n} \sum_{t=1}^n\left\|\boldsymbol{x}_{t,:}-\boldsymbol{f}\left(\boldsymbol{M}, \boldsymbol{x}_{t,:}\right)\right\|_F^2
$$
$\boldsymbol{x}_{t,:} \in \mathbb{R}^{1 \times d}$ è¡¨ç¤ºç¬¬ $t$ ä¸ªè§‚æµ‹æ ·æœ¬ï¼Œ$f$ ä¸ºç”Ÿæˆæ¨¡å‹

### Functional Causal Model

åŸºäºFCMçš„ç®—æ³•å‡è®¾å˜é‡é—´çš„å› æœå…³ç³»æ»¡è¶³å‡½æ•° $\boldsymbol{x}_j=f(\boldsymbol{x}_i,\boldsymbol{e}_j;\boldsymbol{\theta}_{i,j})$  , å…¶ä¸­ $\boldsymbol{x}_i, \boldsymbol{x}_j$ åˆ†åˆ«ä¸ºç›´æ¥åŸå› å˜é‡ã€æœå˜é‡ï¼Œ $\boldsymbol{e}_j \in \mathbb{R}^{n}$ è¡¨ç¤ºä¸€äº›ä¸å¯æµ‹é‡å› ç´ æˆ–å™ªéŸ³ã€‚ $\boldsymbol{\epsilon}=[\boldsymbol{e}_1, \cdots, \boldsymbol{e}_d]$ ï¼Œ $\boldsymbol{\theta}$ ä¸ºæ¨¡å‹å‚æ•°ã€‚ä¸‹å¼ä¸­ç”¨ $L(\cdot)$ è¡¨ç¤ºç”¨äºè¡¡é‡å‚æ•° $\boldsymbol{\theta}$ çš„æ¨¡å‹çš„é¢„æµ‹å€¼ä¸å®é™…è§‚æµ‹çš„æ•°æ® $\boldsymbol{x}_j$ é—´çš„æ‹Ÿåˆç¨‹åº¦çš„å‡½æ•°ã€‚è¯¥ç±»æ–¹æ³•çš„ä¼˜åŒ–é—®é¢˜è¡¨è¿°ä¸º: 

$$
\begin{array}{}
\min : & \sum_{i, j=1: \mathrm{d}} M_{i, j} \cdot\left(L\left(\boldsymbol{x}_j, f\left(\boldsymbol{x}_i, \theta_{i, j}\right)\right)+Q\left(\boldsymbol{x}_i, \boldsymbol{x}_j-f\left(\boldsymbol{x}_i, \theta_{i, j}\right)\right)\right) \\
s.t. & G(M) \in \mathbb{D} \\
var: & \boldsymbol{\theta}, \boldsymbol{M} \in\{0,1\}^{d \times d}
\end{array}
$$
è®¾æœ‰å‡è®¾ $H_1: \boldsymbol{x}_i \perp (\boldsymbol{x}_j - f(\boldsymbol{x}_i,\boldsymbol{\theta}_{i,j})$ ï¼Œ$Q\left(\boldsymbol{x}_i, \boldsymbol{x}_j-f\left(\boldsymbol{x}_i, \theta_{i, j}\right)\right)$ è¡¨ç¤º $\boldsymbol{x}_i$ å’Œ $\boldsymbol{x}_j-f\left(\boldsymbol{x}_i, \theta_{i, j}\right)$ ä¹‹é—´çš„ç‹¬ç«‹æ€§æ£€éªŒçš„æµ‹è¯•ç»Ÿè®¡é‡ï¼Œå½“å…¶å°äºæ˜¾è‘—æ€§æ°´å¹³ $\alpha$ æ—¶æ¥å— $H1$ ï¼ˆè¿™ç§æ–¹æ³•å¯¹åº”äºä¸€ç±»å‡è®¾æ£€éªŒæ–¹æ³•ï¼šregression-based independence testï¼‰ã€‚



## Reference

<a name="ref1">[1]</a> Pearl, J. (2019). The seven tools of causal inference, with reflections on machine learning. *Communications of the ACM*, *62*(3), 54-60.

<a name="ref2">[2]</a> Glymour, Clark, Kun Zhang, and Peter Spirtes. "Review of causal discovery methods based on graphical models." *Frontiers in genetics* 10 (2019): 524.

<a name="ref3">[3]Â </a>Goldberg, L. R. (2019). The Book of Why: The New Science of Cause and Effect: by Judea Pearl and Dana Mackenzie, *Basic Books* (2018). ISBN: 978-0465097609.

<a name="ref4">[4]</a> Tu, R., Zhang, K., KjellstrÃ¶m, H., & Zhang, C. (2022). Optimal transport for causal discovery. In *ICLR 2022-The Tenth International Conference on Learning Representations (Virtual), Apr 25th-29th, 2022.

<a name="ref5">[5]</a> Kalisch, Markus, and Peter BÃ¼hlman. "Estimating high-dimensional directed acyclic graphs with the PC-algorithm." Journal of Machine Learning Research 8.3 (2007).

<a name="ref6">[6]</a> Xun Zheng, Bryon Aragam, Pradeep Ravikumar, and Eric P. Xing. 2018. DAGs with NO TEARS: continuous optimization for structure learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems (NIPS'18). Curran Associates Inc., Red Hook, NY, USA, 9492â€“9503.

<a name="ref7">[7]</a> D. M. Chickering and D. Heckerman. Efficient approximations for the marginal likelihood of Bayesian networks with hidden variables. Machine Learning, 29(2-3):181â€“212, 1997.

<a name="ref8">[8]</a> D. Heckerman, D. Geiger, and D. M. Chickering. Learning Bayesian networks: The combination of knowledge and statistical data. Machine learning, 20(3):197â€“243, 1995.

<a name="ref9">[9]</a> J. Kuipers, G. Moffa, and D. Heckerman. Addendum on the scoring of gaussian directed acyclic graphical models. The Annals of Statistics, pages 1689â€“1691, 2014.

<a name="ref10">[10]</a> F. Fu and Q. Zhou. Learning sparse causal Gaussian networks with experimental intervention: Regularization and coordinate descent. Journal of the American Statistical Association, 108(501):288â€“300, 2013. 

<a name="ref11">[11]</a> Zheng, X., Aragam, B., Ravikumar, P. K., & Xing, E. P. (2018). Dags with no tears: Continuous optimization for structure learning. *Advances in Neural Information Processing Systems*, *31*.

<a name="ref12">[12]</a> Shimizu, S., Hoyer, P. O., HyvÃ¤rinen, A., Kerminen, A., & Jordan, M. (2006). A linear non-Gaussian acyclic model for causal discovery. *Journal of Machine Learning Research*, *7*(10).

<a name="ref13">[13]</a> Matthew J. Vowels, Necati Cihan Camgoz, and Richard Bowden. 2022. Dâ€™ya Like DAGs? A Survey on Structure Learning and Causal Discovery. ACM Comput. Surv. Just Accepted (March 2022). https://doi.org/10.1145/3527154

<a name="ref14">[14]</a> Starmans, R. (2020). Prometheus unbound or Paradise regained: the concept of Causality in the contemporary AI-Data Science debate. *Journal de la SociÃ©tÃ© FranÃ§aise de Statistique*, *161*(1), 4-41.

<a name="ref15">[15]</a> Cheeseman, P. (1985). In defense of probability. In Proceedings of the Ninth International Joint Conference on AI (IJCAI, 1983).

<a name="ref16">[16]</a> Williamson, J. (2009). Probabilistic theories of causality. *The Oxford handbook of causation*, 185-212.

<a name="ref17">[17]</a> Good, I. J. (1959). A theory of causality. *The British Journal for the Philosophy of Science*, *9*(36), 307-310.

<a name="ref18">[18]</a> Good, I. J. (1961). A causal calculus (I). *The British journal for the philosophy of science*, *11*(44), 305-318.

<a name="ref19">[19]</a> Good, I. J. (1961). A causal calculus (II). *The British journal for the philosophy of science*, *12*(45), 43-51.

<a name="ref20">[20]</a> Pearl, J. (2009). Causal inference in statistics: An overview. *Statistics surveys*, *3*, 96-146.



## 2020-2022æœ€æ–°è®ºæ–‡åˆ—è¡¨

1. Jalaldoust, A., HlavÃ¡ÄkovÃ¡-Schindler, K., & Plant, C. (2022, June). Causal Discovery in Hawkes Processes by Minimum Description Length. In *Proceedings of the AAAI Conference on Artificial Intelligence* (Vol. 36, No. 6, pp. 6978-6987).ã€é«˜ç»´Hawkesåºåˆ—ä¸­çš„Grange causal graph learningã€‘
2. Zhang, H., Zhang, K., Zhou, S., Guan, J., & Zhang, J. (2021, May). Testing independence between linear combinations for causal discovery. In *Proceedings of the AAAI Conference on Artificial Intelligence* (Vol. 35, No. 7, pp. 6538-6546).ã€çº¿æ€§éé«˜æ–¯ç»“æ„æ–¹ç¨‹æ¨¡å‹ä¸‹ä¸¤ä¸ªçº¿æ€§ç»„åˆä¹‹é—´çš„ç‹¬ç«‹æ€§â€”â€”æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•ä¸­çš„ä¸€ä¸ªç‰¹æ®Šé—®é¢˜ã€‘
3. Lu, N. Y., Zhang, K., & Yuan, C. (2021, May). Improving causal discovery by optimal bayesian network learning. In *Proceedings of the AAAI Conference on Artificial Intelligence* (Vol. 35, No. 10, pp. 8741-8748).ã€æå‡ºäº†ä¸€ç§åŸºäºåˆ†æ•°çš„æ–¹æ³•ä¸­, ä¸€ç§æ–°çš„ç©·ä¸¾ä¼˜åŒ–æ–¹æ³•ã€‘
4. Hyttinen, A., Eberhardt, F., & JÃ¤rvisalo, M. (2014, July). Constraint-based Causal Discovery: Conflict Resolution with Answer Set Programming. In *UAI* (pp. 340-349).ã€å°†å› æœå›¾æœç´¢é—®é¢˜, è§†ä¸ºå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ã€‘
5. Dhir, A., & Lee, C. M. (2020, April). Integrating overlapping datasets using bivariate causal discovery. In *Proceedings of the AAAI Conference on Artificial Intelligence* (Vol. 34, No. 04, pp. 3781-3790).ã€ä»å¤šä¸ªæ•°æ®é›†ä¸­å­¦ä¹ ä¸€è‡´çš„å› æœç»“æ„çš„é—®é¢˜ã€‘
6. Huang, B., Zhang, K., Gong, M., & Glymour, C. (2020, April). Causal discovery from multiple data sets with non-identical variable sets. In *Proceedings of the AAAI Conference on Artificial Intelligence* (Vol. 34, No. 06, pp. 10153-10161).ã€å…·æœ‰ä¸åŒå˜é‡é›†çš„å¤šä¸ªæ•°æ®é›†çš„å› æœå‘ç°ã€‘
7. Maeda, T. N., & Shimizu, S. (2020, June). RCD: Repetitive causal discovery of linear non-Gaussian acyclic models with latent confounders. In *International Conference on Artificial Intelligence and Statistics* (pp. 735-745). PMLR.ã€å—æ½œåœ¨æ··æ‚å› ç´ å½±å“çš„æ•°æ®ä¸­, å‘ç°åˆ©ç”¨å‡½æ•°æ¨¡å‹æ¥å‘ç°å› æœ(ä»¥å¾€é€šå¸¸æ˜¯åŸºäºçº¦æŸ)ã€‘
8. Tu, R., Zhang, C., Ackermann, P., Mohan, K., KjellstrÃ¶m, H., & Zhang, K. (2019, April). Causal discovery in the presence of missing data. In *The 22nd International Conference on Artificial Intelligence and Statistics* (pp. 1762-1770). PMLR.ã€**ç¼ºå¤±æ•°æ®ä¸­çš„å› æœå‘ç°**ã€‘
9. Feng, G., Yu, K., Wang, Y., Yuan, Y., & DjuriÄ‡, P. M. (2020, May). Improving convergent cross mapping for causal discovery with Gaussian processes. In *ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)* (pp. 3692-3696). IEEE.ã€è€¦åˆæ—¶é—´åºåˆ—ä¹‹é—´çš„å› æœå‘ç°ã€‘
10. Lippe, P., Cohen, T., & Gavves, E. (2021). Efficient neural causal discovery without acyclicity constraints. *arXiv preprint arXiv:2107.10483*.ã€ä¸€ä¸ªåŸºäºç¥ç»ç½‘ç»œ+score basedçš„å› æœå‘ç°ã€‘
11. Tu, R., Zhang, K., KjellstrÃ¶m, H., & Zhang, C. (2022). Optimal transport for causal discovery. In *ICLR 2022-The Tenth International Conference on Learning Representations (Virtual), Apr 25th-29th, 2022*.ã€ç”¨**æœ€ä¼˜ä¼ è¾“**ç†è®ºé‡å†™äº†FCMçš„æ–¹æ³•, å¹¶ä»¥ä¼˜åŒ–çš„å½¢å¼åšä¼˜åŒ–, å®ç°å› æœå‘ç°ã€‘
12. Zhu, S., Ng, I., & Chen, Z. (2019, September). Causal Discovery with Reinforcement Learning. In *International Conference on Learning Representations*.ã€è¿™ä¸ªæ–‡ç« é‡Œå¯¹**å„ç±»ä¼˜åŒ–æ–¹æ³•**æœ‰æ¯”è¾ƒå¥½çš„è°ƒç ”ã€‘
13. Huang, B., Zhang, K., Gong, M., & Glymour, C. (2019, May). Causal discovery and forecasting in nonstationary environments with state-space models. In *International conference on machine learning* (pp. 2901-2910). PMLR.ã€éå¹³ç¨³æ—¶é—´åºåˆ—ä¸­çš„å› æœå‘ç°ã€‘
14. Empirical Bayesian Approaches for Robust Constraint-based Causal Discovery under Insufficient Dataã€å°æ•°æ®ã€éå¹³ç¨³ã€‘
15. Brouillard, P., Lachapelle, S., Lacoste, A., Lacoste-Julien, S., & Drouin, A. (2020). Differentiable causal discovery from interventional data. *Advances in Neural Information Processing Systems*, *33*, 21865-21877.ã€å¼±å¿ è¯šå‡è®¾çš„å› æœå‘ç°ã€‘
16. Mokhtarian, E., Akbari, S., Ghassami, A., & Kiyavash, N. (2021, August). A recursive markov boundary-based approach to causal structure learning. In The KDD'21 Workshop on Causal Discovery (pp. 26-54). PMLR.ã€åŸºäºçº¦æŸçš„æ–¹æ³•, ç”¨é€’å½’çš„ä¼˜åŒ–æ–¹æ³•ã€‘



## å€¼å¾—å…³æ³¨çš„æœ€æ–°å·¥ä½œ



1. Bhattacharya, R., Nagarajan, T., Malinsky, D., & Shpitser, I. (2021, March). Differentiable causal discovery under unmeasured confounding. In *International Conference on Artificial Intelligence and Statistics* (pp. 2314-2322). PMLR.ã€confounded systemsä¸­çš„å› æœå›¾æ¨¡å‹å‘ç°, å…¶ä¸­èŠ‚ç‚¹çš„å®šä¹‰å¯èƒ½ä¸ä¸€æ ·ã€‘
2. Brouillard, P., Lachapelle, S., Lacoste, A., Lacoste-Julien, S., & Drouin, A. (2020). Differentiable causal discovery from interventional data. *Advances in Neural Information Processing Systems*, *33*, 21865-21877.ã€å’Œä¸Šé¢çš„æœ‰ç‚¹åƒã€‘
3. S. Ren, H. Yin, M. Sun and P. Li, "Causal Discovery with Flow-based Conditional Density Estimation," *2021 IEEE International Conference on Data Mining (ICDM)*, 2021, pp. 1300-1305, doi: 10.1109/ICDM51629.2021.00161.ã€æµæ¨¡å‹æ¥ä¼°è®¡å˜é‡çš„è”åˆæ¦‚ç‡å¯†åº¦, æ ¹æ®æ¡ä»¶å¯†åº¦ä¼°è®¡çš„æ–¹å·®æ¨æ–­æ¯ä¸ªæ½œåœ¨å› æœæ–¹å‘çš„åˆ†æ•°, æˆ‘ä»¬çš„å› æœå‘ç°æ–¹æ³•å‡è½»äº†ä¼ ç»Ÿæ–¹æ³•æ‰€åšçš„é™åˆ¶æ€§å‡è®¾, æ›´å¥½åœ°æ•æ‰å„ç§é—®é¢˜é¢†åŸŸä¸­ä»¥ä»»æ„å½¢å¼å‡ºç°çš„æ•°æ®ä¹‹é—´çš„å¤æ‚å› æœå…³ç³»ã€‘
4. Zhang, H., Zhou, S., Zhang, K., & Guan, J. (2022, June). Residual Similarity Based Conditional Independence Test and Its Application in Causal Discovery. In *Proceedings of the AAAI Conference on Artificial Intelligence* (Vol. 36, No. 5, pp. 5942-5949).ã€CIè½¬ä¼˜åŒ–é—®é¢˜ã€‘



-----



## ToolBox

+ gCastle [URL](https://github.com/huawei-noah/trustworthyAI/tree/master/gcastle)


> gCastleæ˜¯åä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤è‡ªç ”çš„å› æœç»“æ„å­¦ä¹ å·¥å…·é“¾, ä¸»è¦çš„åŠŸèƒ½å’Œæ„¿æ™¯åŒ…æ‹¬: 
>
> 1. æ•°æ®ç”ŸæˆåŠå¤„ç†: åŒ…å«å„ç§æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆç®—å­, æ•°æ®è¯»å–ç®—å­, æ•°æ®å¤„ç†ç®—å­(å¦‚å…ˆéªŒçŒå…¥, å˜é‡é€‰æ‹©, CRAM)ã€‚
> 2. å› æœå›¾æ„å»º: æä¾›äº†ä¸€ä¸ªå› æœç»“æ„å­¦ä¹ pythonç®—æ³•åº“, åŒ…å«äº†ä¸»æµçš„å› æœå­¦ä¹ ç®—æ³•ä»¥åŠæœ€è¿‘å…´èµ·çš„åŸºäºæ¢¯åº¦çš„å› æœç»“æ„å­¦ä¹ ç®—æ³•ã€‚
> 3. å› æœè¯„ä»·: æä¾›äº†å¸¸ç”¨çš„å› æœç»“æ„å­¦ä¹ æ€§èƒ½è¯„ä»·æŒ‡æ ‡, åŒ…æ‹¬F1, SHD, FDR, TPR, FDR, NNZç­‰

+ Causal Discovery Toolbox [URL](https://github.com/FenTechSolutions/CausalDiscoveryToolbox)

> The Causal Discovery Toolbox is a package for causal inference in graphs and in the pairwise settings for Python>=3.5. 
> Tools for graph structure recovery and dependencies are included. The package is based on Numpy, Scikit-learn, Pytorch and R.


+ Tigramite [URL](https://github.com/jakobrunge/tigramite)

> Tigramite æ˜¯ä¸€ä¸ªå› æœæ—¶é—´åºåˆ—åˆ†æ python åŒ…ã€‚å®ƒå…è®¸ä»é«˜ç»´æ—¶é—´åºåˆ—æ•°æ®é›†æœ‰æ•ˆåœ°é‡å»ºå› æœå›¾, å¹¶å¯¹è·å¾—çš„å› æœä¾èµ–è¿›è¡Œå»ºæ¨¡, 
> ä»¥è¿›è¡Œå› æœä¸­ä»‹å’Œé¢„æµ‹åˆ†æã€‚å› æœå‘ç°åŸºäºé€‚ç”¨äºç¦»æ•£æˆ–è¿ç»­å€¼æ—¶é—´åºåˆ—çš„çº¿æ€§å’Œéå‚æ•°æ¡ä»¶ç‹¬ç«‹æ€§æµ‹è¯•ã€‚
>
> - åŒ…å«çš„å› æœå‘ç°æ–¹æ³•: PCMCIã€PCMCIplusã€LPCMCI
> - åŒ…å«çš„ç‹¬ç«‹æ€§æµ‹è¯•æ–¹æ³•: ParCorrã€GPDC / GPDCtorchã€CMIknnã€CMIsymb

+ causalDisco: an R package with tools for causal discovery on observational data [URL](https://github.com/annennenne/causalDisco)

> causalDisco åŒ…æ‹¬temporal PCçš„å®ç°

+ Causal Discovery Tools for Time Series Applications - A Collection of Tutorials [URL](https://github.com/savinims/DATAS_Causal_Discovery)

> ä¸ºå¤§æ°”ç§‘å­¦å®¶æ•°æ®åˆ†æå·¥å…· (DATAS) ç½‘å…³çš„ä¸€éƒ¨åˆ†, ç¼–å†™çš„æ•™ç¨‹ä¾§é‡äºå¤§æ°”ç§‘å­¦åº”ç”¨ã€‚æ•°æ®: https://datasgateway.colostate.edu/
>
> æœ¬èµ„æ–™åº“ä¸­è§£é‡Šçš„æ–¹æ³•ä¾§é‡äºè§‚å¯Ÿæ€§ç ”ç©¶, å…¶ä¸­ä¸è¿›è¡Œå—æ§å®éªŒ(ä¾‹å¦‚, æ°”å€™ä¸­çš„æœ‰é’ˆå¯¹æ€§çš„å»ºæ¨¡ç ”ç©¶)æ¥ç¡®å®šåŸå› å’Œå½±å“ã€‚
> è¿™äº›æ–¹æ³•å…è®¸æ‚¨è¯†åˆ«éœ€è¦ä½¿ç”¨æˆ‘ä»¬ç°æœ‰çš„ç‰¹å®šåº”ç”¨é¢†åŸŸçŸ¥è¯†è¿›ä¸€æ­¥éªŒè¯çš„"æ½œåœ¨"å…³ç³»ã€‚
>
> æ–¹æ³•åŒ…æ‹¬: äºŒå…ƒæ ¼å…°æ°å› æœæ£€éªŒã€PCç¨³å®šç®—æ³•çš„æ—¶é—´åºåˆ—æ‰©å±•


## Related work with code

[1] TCDF: Causal Discovery with Attention-Based Convolutional Neural Networks [URL](https://github.com/M-Nauta/TCDF)

> æ—¶é—´å› æœå‘ç°æ¡†æ¶ (TCDF) æ˜¯åœ¨ PyTorch ä¸­å®ç°çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚ç»™å®šå¤šä¸ªæ—¶é—´åºåˆ—ä½œä¸ºè¾“å…¥, TCDF å‘ç°è¿™äº›æ—¶é—´åºåˆ—ä¹‹é—´çš„å› æœå…³ç³»å¹¶è¾“å‡ºå› æœå›¾ã€‚
> å®ƒè¿˜å¯ä»¥æ ¹æ®å…¶ä»–æ—¶é—´åºåˆ—é¢„æµ‹ä¸€ä¸ªæ—¶é—´åºåˆ—ã€‚TCDF ä½¿ç”¨åŸºäºæ³¨æ„åŠ›çš„å·ç§¯ç¥ç»ç½‘ç»œç»“åˆå› æœéªŒè¯æ­¥éª¤ã€‚é€šè¿‡è§£é‡Šå·ç§¯ç½‘ç»œçš„å†…éƒ¨å‚æ•°, TCDF è¿˜å¯ä»¥å‘ç°å› æœä¹‹é—´çš„æ—¶é—´å»¶è¿Ÿã€‚

[2] Amortize Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data [URL](https://github.com/loeweX/AmortizedCausalDiscovery)

> é€šè¿‡ Amortized Causal Discovery, æˆ‘ä»¬å­¦ä¹ ä»å…·æœ‰ä¸åŒæ½œåœ¨å› æœå›¾ä½†å…±äº«åŠ¨æ€çš„æ ·æœ¬ä¸­æ¨æ–­å› æœå…³ç³»ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè·¨æ ·æœ¬è¿›è¡Œæ³›åŒ–, ä»è€Œé€šè¿‡å¢åŠ è®­ç»ƒæ•°æ®å¤§å°æ¥æé«˜æˆ‘ä»¬çš„æ€§èƒ½ã€‚

[3] Causal Discovery from Nonstationary/Heterogeneous Data: Skeleton Estimation and Orientation Determination. IJCAI 2017. [URL](https://github.com/Biwei-Huang/Causal-Discovery-from-Nonstationary-Heterogeneous-Data)

[4] Causal Discovery in Heavy-Tailed Models [URL](https://github.com/nicolagnecco/causalXtreme)

[5] Differentiable Causal Discovery from Interventional Data [URL](https://github.com/slachapelle/dcdi)

[6] Generalized Score Functions for Causal Discovery. KDD, 2018 [URL](https://github.com/Biwei-Huang/Generalized-Score-Functions-for-Causal-Discovery)

> å…·æœ‰å¹¿ä¹‰å¾—åˆ†å‡½æ•°çš„è´ªå©ªç­‰ä»·æœç´¢çš„å› æœç»“æ„å­¦ä¹ (é€‚ç”¨äºæ··åˆè¿ç»­å’Œç¦»æ•£æ•°æ®ã€å…·æœ‰é«˜æ–¯æˆ–éé«˜æ–¯åˆ†å¸ƒçš„æ•°æ®ã€çº¿æ€§æˆ–éçº¿æ€§å› æœæœºåˆ¶ä»¥åŠå…·æœ‰å¤šç»´çš„å˜é‡ã€‚)

[7] Learning the Causal Structure of Copula Models with Latent Variables. UAI. 2018 [URL](https://github.com/cuiruifei/CopulaFactorModel)

[8] Data Generating Process to Evaluate Causal Discovery Techniques for Time Series Data, at the Causal Discovery & Causality-Inspired Machine Learning Workshop at NeurIPS 2020. [URL](https://github.com/causalens/cdml-neurips2020)

[9] Process Mining Meets Causal Machine Learning: Discovering Causal Rules from Event Logs [URL](https://github.com/zahradbozorgi/CausalRulesDiscovery)



